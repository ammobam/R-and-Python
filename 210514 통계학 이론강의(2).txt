# 검정통계
- 가설을 세우고 통계로 검정함

# 가설 용어
- 귀무가설(H0) : 일반적으로 인정하는 주장. 부정 결론을 도출하기 위한 가설.
- 대립가설(H1) : 통계적 근거를 통해 입증하려는 주장. 귀무가설과 반대됨.

- 신뢰구간 : 귀무가설이 성립할 것으로 추정하는 구간
- 신뢰수준(1-a) : 귀무가설이 채택될 확률 (예시: 90% 신뢰수준)
- 기각역: 귀무가설을 기각할 것으로 추정하는 구간(꼬리부분)

- 유의수준(a) : 귀무가설을 기각할 확률. 보통 0.01~0.05 설정.
- 임계치 : 기각역과 신뢰구간의 경계선에 대응되는 값
- 유의확률(p-값) : 유의수준을 정확히 계산한 값
- 검정 통계량 : 유의 확률에대응되는 값

# 가설 검정 방법
가설설정 
> 분석방법채택 
> 유의수준(a) 설정 
> 유의확률(p-값)|검정통계량 계산 
> 가설판정(임계치 이상의 값의 존재확인, a에 포함되는지. p-값이 a보다 작은지.)

## 예시
귀무가설: 평균수명 60
대립가설: 평균수명 80
임계치: 70
Q: 75세(p-값)는 귀무가설의 꼬리, 대립가설의 내부.
귀무가설 기각, 대립가설 채택
-- 귀무가설 H0, 대립가설 H1 두 정규분포를 같은 x축에 그려서 비교함. 겹치는 부분이 임계치.
-- https://losskatsu.github.io/statistics/alpha-beta-test/#유의확률

# 검정형태 분류
- 왼쪽 단측검정, 오른쪽 단측검정, 양측검정


# 평균차이 검정
# 분산 분석 	-- 3개 이상은 분산 분석 이용
# 상관관계 분석 	-- 상관계수 =/= 인과관계
# 다중회귀분석
- 변수 선택방법 고려
- 다중공선성 : 변수간 유의한 상관관계가 있어 발생하는 문제
-- 분산확대인자 : 10 이상이면 다중공선성 문제 발생


#--------------------------------------
tensorflow
	https://copycoding.tistory.com/341
keras

#--------------------------------------
머신러닝 = 선형회귀 반복
https://datascienceschool.net/03%20machine%20learning/04.02%20%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D%EC%9D%98%20%EA%B8%B0%EC%B4%88.html

from sklearn.linear_model import make_regression
- bias=100 : 편향, y절편
- feature=1 : 독립변수, 1차함수
	-- Input(입력)변수 = 설명변수 = 예측변수(predictor) = 독립변수 = 특징(feature)
	-- Output(출력)변수 = 반응변수 = 응답변수(response) = 종속변수
- coef=True : 계수

'''
import statsmodels.api as sm
from sklearn.datasets import make_regression

bias = 100
X0, y, w = make_regression(
    n_samples=200, n_features=2, bias=bias, noise=10, coef=True, random_state=1
)
X = sm.add_constant(X0)
y = y.reshape(len(y), 1)
w
'''

# 시그모이드
- S자 그래프
https://icim.nims.re.kr/post/easyMath/64
- 회귀분석에서는 종속변수의 범위가 실수
- 로지스틱 회귀분석에서는 종속변수 y값이 0 또는 1

#--------------------------------------
# 행렬 변환
- 벡터는 행렬로 표기할 수 있다
- 역학 좌표변환 복습하자

i = [[1],
     [0]]

j = [[0],
     [1]]

E = [[1, 0],
      [0, 1]]

- 단위행렬 값이 변하는 것을 추적해서 좌표계 변환을 알아낸다
-- 이미지의 각 점이 좌표계의 점이므로, 좌표 변환으로 이미지를 기울일 수 있음

## 변환의 종류
- 밀림 변환
- 반시계 직교 변환 (삼각함수)
- 연속 변환: 반시계직교 + 밀림
- 확대: n배.. nE 곱함
	[[n, 0]
	 [0, n]]

# 고유값(Eigenvalue)과 고유벡터(Eigenvector)
- 변환시켜도 방향이 바뀌지 않고 크기만 바뀌는 벡터를 고유벡터라 함.
-- 좌표계에서 변환 방향과 동일한 방향의 벡터는 크기만 변함.
A = [[2, 1],
       [1, 2]]

Ax = λx (A, x: 벡터, λ: 실수)
- 변환행렬 A를 곱해도 스칼라배처럼 작용하는 벡터 x를 고유벡터라고 함

## 주성분 분석 (Principal Component Ananlysis)
- 주성분 분석은 정보량이 가장 많은 방향으로 반복해서 동일한 개수의 새로운 축을 잡는 머신러닝 기법
## 차원축소
-- 데이터 내에 적당한 선 위에 수선의 발을 내려서 차원 축소하면,
-- 비교적 작은 오차범위에서 쉬운 계산식으로 데이터 분석 수행 가능
https://seongyun-dev.tistory.com/4


